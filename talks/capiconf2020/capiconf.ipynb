{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://capiconf-m.us-central1-f.c.danicat.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9a0176e290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://capiconf-m.us-central1-f.c.danicat.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sc.textFile(\"gs://danicat/capiconf/t8.shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gs://danicat/capiconf/t8.shakespeare.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'This is the 100th Etext file presented by Project Gutenberg, and',\n",
       " u'is presented in cooperation with World Library, Inc., from their',\n",
       " u'Library of the Future and Shakespeare CDROMS.  Project Gutenberg',\n",
       " u'often releases Etexts that are NOT placed in the Public Domain!!',\n",
       " u'',\n",
       " u'Shakespeare',\n",
       " u'',\n",
       " u'*This Etext has certain copyright implications you should read!*',\n",
       " u'',\n",
       " u'<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = text.flatMap(lambda line: line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:52"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'this',\n",
       " u'is',\n",
       " u'the',\n",
       " u'100th',\n",
       " u'etext',\n",
       " u'file',\n",
       " u'presented',\n",
       " u'by',\n",
       " u'project',\n",
       " u'gutenberg,']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = word.map(lambda w: (w, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'this', 1),\n",
       " (u'is', 1),\n",
       " (u'the', 1),\n",
       " (u'100th', 1),\n",
       " (u'etext', 1),\n",
       " (u'file', 1),\n",
       " (u'presented', 1),\n",
       " (u'by', 1),\n",
       " (u'project', 1),\n",
       " (u'gutenberg,', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = ones.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', 11),\n",
       " (u'considered-', 1),\n",
       " (u'mustachio', 1),\n",
       " (u'protested,', 1),\n",
       " (u'sending.', 3),\n",
       " (u'offendeth', 1),\n",
       " (u'dance;', 4),\n",
       " (u'scold', 4),\n",
       " (u'nunnery', 1),\n",
       " (u'swoopstake', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[12] at RDD at PythonRDD.scala:52"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) PythonRDD[12] at RDD at PythonRDD.scala:52 []\n",
      " |  MapPartitionsRDD[10] at mapPartitions at PythonRDD.scala:132 []\n",
      " |  ShuffledRDD[9] at partitionBy at NativeMethodAccessorImpl.java:0 []\n",
      " +-(2) PairwiseRDD[8] at reduceByKey at <ipython-input-12-8893febe9100>:1 []\n",
      "    |  PythonRDD[7] at reduceByKey at <ipython-input-12-8893febe9100>:1 []\n",
      "    |  gs://danicat/capiconf/t8.shakespeare.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0 []\n",
      "    |  gs://danicat/capiconf/t8.shakespeare.txt HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "print(count.toDebugString().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', 11),\n",
       " (u'considered-', 1),\n",
       " (u'mustachio', 1),\n",
       " (u'protested,', 1),\n",
       " (u'sending.', 3),\n",
       " (u'offendeth', 1),\n",
       " (u'dance;', 4),\n",
       " (u'scold', 4),\n",
       " (u'nunnery', 1),\n",
       " (u'swoopstake', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = count.toDF([\"word\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|       fawn|   11|\n",
      "|considered-|    1|\n",
      "|  mustachio|    1|\n",
      "| protested,|    1|\n",
      "|   sending.|    3|\n",
      "|  offendeth|    1|\n",
      "|     dance;|    4|\n",
      "|      scold|    4|\n",
      "|    nunnery|    1|\n",
      "| swoopstake|    1|\n",
      "|  valorous,|    1|\n",
      "|   whither?|    8|\n",
      "|  out-night|    1|\n",
      "|   benvolio|    4|\n",
      "|    spider.|    1|\n",
      "|    spider,|    4|\n",
      "|      wood,|   13|\n",
      "|      wood.|    8|\n",
      "|    suck'd.|    1|\n",
      "|   imagin'd|    7|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|             word|             count|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|            59508|             59508|\n",
      "|   mean|599.0159574468086|15.146282852725683|\n",
      "| stddev|4521.544462453864| 268.6400215895862|\n",
      "|    min|                \"|                 1|\n",
      "|    max|                }|             27549|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|       fawn|   11|\n",
      "|considered-|    1|\n",
      "|  mustachio|    1|\n",
      "| protested,|    1|\n",
      "|   sending.|    3|\n",
      "|  offendeth|    1|\n",
      "|     dance;|    4|\n",
      "|      scold|    4|\n",
      "|    nunnery|    1|\n",
      "| swoopstake|    1|\n",
      "|  valorous,|    1|\n",
      "|   whither?|    8|\n",
      "|  out-night|    1|\n",
      "|   benvolio|    4|\n",
      "|    spider.|    1|\n",
      "|    spider,|    4|\n",
      "|      wood,|   13|\n",
      "|      wood.|    8|\n",
      "|    suck'd.|    1|\n",
      "|   imagin'd|    7|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|27549|\n",
      "| and|26037|\n",
      "|   i|19540|\n",
      "|  to|18700|\n",
      "|  of|18010|\n",
      "|   a|14383|\n",
      "|  my|12455|\n",
      "|  in|10671|\n",
      "| you|10630|\n",
      "|that|10487|\n",
      "|  is| 9145|\n",
      "| for| 7982|\n",
      "|with| 7931|\n",
      "| not| 7643|\n",
      "|your| 6871|\n",
      "| his| 6749|\n",
      "|  be| 6700|\n",
      "| but| 5886|\n",
      "|  he| 5884|\n",
      "|this| 5882|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"count\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"wordcount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|27549|\n",
      "| and|26037|\n",
      "|   i|19540|\n",
      "|  to|18700|\n",
      "|  of|18010|\n",
      "|   a|14383|\n",
      "|  my|12455|\n",
      "|  in|10671|\n",
      "| you|10630|\n",
      "|that|10487|\n",
      "|  is| 9145|\n",
      "| for| 7982|\n",
      "|with| 7931|\n",
      "| not| 7643|\n",
      "|your| 6871|\n",
      "| his| 6749|\n",
      "|  be| 6700|\n",
      "| but| 5886|\n",
      "|  he| 5884|\n",
      "|  as| 5882|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from wordcount order by 2 desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[12] at RDD at PythonRDD.scala:52"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string, count: bigint]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|       fawn|   11|\n",
      "|considered-|    1|\n",
      "|  mustachio|    1|\n",
      "| protested,|    1|\n",
      "|   sending.|    3|\n",
      "|  offendeth|    1|\n",
      "|     dance;|    4|\n",
      "|      scold|    4|\n",
      "|    nunnery|    1|\n",
      "| swoopstake|    1|\n",
      "|  valorous,|    1|\n",
      "|   whither?|    8|\n",
      "|  out-night|    1|\n",
      "|   benvolio|    4|\n",
      "|    spider.|    1|\n",
      "|    spider,|    4|\n",
      "|      wood,|   13|\n",
      "|      wood.|    8|\n",
      "|    suck'd.|    1|\n",
      "|   imagin'd|    7|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u\"you're\",\n",
       " u\"you've\",\n",
       " u\"you'll\",\n",
       " u\"you'd\",\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u\"she's\",\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u\"it's\",\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u\"that'll\",\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u\"don't\",\n",
       " u'should',\n",
       " u\"should've\",\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u\"aren't\",\n",
       " u'couldn',\n",
       " u\"couldn't\",\n",
       " u'didn',\n",
       " u\"didn't\",\n",
       " u'doesn',\n",
       " u\"doesn't\",\n",
       " u'hadn',\n",
       " u\"hadn't\",\n",
       " u'hasn',\n",
       " u\"hasn't\",\n",
       " u'haven',\n",
       " u\"haven't\",\n",
       " u'isn',\n",
       " u\"isn't\",\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u\"mightn't\",\n",
       " u'mustn',\n",
       " u\"mustn't\",\n",
       " u'needn',\n",
       " u\"needn't\",\n",
       " u'shan',\n",
       " u\"shan't\",\n",
       " u'shouldn',\n",
       " u\"shouldn't\",\n",
       " u'wasn',\n",
       " u\"wasn't\",\n",
       " u'weren',\n",
       " u\"weren't\",\n",
       " u'won',\n",
       " u\"won't\",\n",
       " u'wouldn',\n",
       " u\"wouldn't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string, count: bigint]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u\"you're\",\n",
       " u\"you've\",\n",
       " u\"you'll\",\n",
       " u\"you'd\",\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u\"she's\",\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u\"it's\",\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u\"that'll\",\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u\"don't\",\n",
       " u'should',\n",
       " u\"should've\",\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u\"aren't\",\n",
       " u'couldn',\n",
       " u\"couldn't\",\n",
       " u'didn',\n",
       " u\"didn't\",\n",
       " u'doesn',\n",
       " u\"doesn't\",\n",
       " u'hadn',\n",
       " u\"hadn't\",\n",
       " u'hasn',\n",
       " u\"hasn't\",\n",
       " u'haven',\n",
       " u\"haven't\",\n",
       " u'isn',\n",
       " u\"isn't\",\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u\"mightn't\",\n",
       " u'mustn',\n",
       " u\"mustn't\",\n",
       " u'needn',\n",
       " u\"needn't\",\n",
       " u'shan',\n",
       " u\"shan't\",\n",
       " u'shouldn',\n",
       " u\"shouldn't\",\n",
       " u'wasn',\n",
       " u\"wasn't\",\n",
       " u'weren',\n",
       " u\"weren't\",\n",
       " u'won',\n",
       " u\"won't\",\n",
       " u'wouldn',\n",
       " u\"wouldn't\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "swdf = spark.createDataFrame(map(lambda x: (x,), sw), [\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|         i|\n",
      "|        me|\n",
      "|        my|\n",
      "|    myself|\n",
      "|        we|\n",
      "|       our|\n",
      "|      ours|\n",
      "| ourselves|\n",
      "|       you|\n",
      "|    you're|\n",
      "|    you've|\n",
      "|    you'll|\n",
      "|     you'd|\n",
      "|      your|\n",
      "|     yours|\n",
      "|  yourself|\n",
      "|yourselves|\n",
      "|        he|\n",
      "|       him|\n",
      "|       his|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "swdf.createOrReplaceTempView(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop = spark.sql(\"select * from wordcount w where not exists (select 1 from stopwords s where s.word = w.word) order by 2 desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|  thou| 5138|\n",
      "|   thy| 4028|\n",
      "| shall| 3473|\n",
      "|  good| 2560|\n",
      "| would| 2240|\n",
      "|   let| 2089|\n",
      "| enter| 2013|\n",
      "|  hath| 1902|\n",
      "|  thee| 1794|\n",
      "|   may| 1747|\n",
      "|  i'll| 1737|\n",
      "|  king| 1698|\n",
      "|  upon| 1664|\n",
      "|  like| 1641|\n",
      "|  make| 1596|\n",
      "|   one| 1486|\n",
      "|  you,| 1479|\n",
      "|  must| 1449|\n",
      "|  know| 1402|\n",
      "|  'tis| 1367|\n",
      "|  come| 1359|\n",
      "|   yet| 1286|\n",
      "|  give| 1286|\n",
      "|  love| 1279|\n",
      "|  sir,| 1235|\n",
      "|    go| 1224|\n",
      "|   me,| 1218|\n",
      "|   say| 1189|\n",
      "|   see| 1169|\n",
      "|  take| 1167|\n",
      "|   th'| 1146|\n",
      "|    us| 1075|\n",
      "|   man| 1033|\n",
      "|    o,| 1008|\n",
      "|  tell|  993|\n",
      "| first|  988|\n",
      "|  well|  984|\n",
      "| lord,|  977|\n",
      "| never|  959|\n",
      "|  time|  936|\n",
      "|  doth|  912|\n",
      "|  lord|  894|\n",
      "|  much|  890|\n",
      "| come,|  875|\n",
      "|  mine|  866|\n",
      "| think|  862|\n",
      "|exeunt|  841|\n",
      "| great|  828|\n",
      "|   me.|  823|\n",
      "|  you.|  813|\n",
      "|  why,|  805|\n",
      "|   art|  805|\n",
      "| speak|  803|\n",
      "|  now,|  785|\n",
      "|   it.|  784|\n",
      "|  him.|  755|\n",
      "| scene|  753|\n",
      "|  made|  749|\n",
      "|  hear|  736|\n",
      "|  exit|  728|\n",
      "|   sir|  721|\n",
      "|cannot|  719|\n",
      "| sweet|  707|\n",
      "| lord.|  702|\n",
      "|  him,|  698|\n",
      "|  look|  694|\n",
      "|   ay,|  661|\n",
      "| well,|  647|\n",
      "|  and,|  647|\n",
      "|   no,|  645|\n",
      "|   two|  641|\n",
      "| king.|  638|\n",
      "|  fair|  624|\n",
      "|  pray|  622|\n",
      "|   old|  620|\n",
      "| whose|  612|\n",
      "|  till|  611|\n",
      "|though|  611|\n",
      "| could|  603|\n",
      "| thee,|  597|\n",
      "|  poor|  578|\n",
      "| noble|  574|\n",
      "|  duke|  571|\n",
      "| world|  568|\n",
      "|  hast|  568|\n",
      "|second|  563|\n",
      "|   men|  557|\n",
      "|  long|  555|\n",
      "|   god|  555|\n",
      "|  thus|  554|\n",
      "|  nay,|  550|\n",
      "|  even|  546|\n",
      "|  many|  533|\n",
      "|  ever|  530|\n",
      "| heart|  528|\n",
      "|   it,|  526|\n",
      "| leave|  522|\n",
      "|  call|  519|\n",
      "| comes|  513|\n",
      "|master|  506|\n",
      "+------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nostop.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Scan ExistingRDD[word#301]\n"
     ]
    }
   ],
   "source": [
    "swdf.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Sort [count#1L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(count#1L DESC NULLS LAST, 200)\n",
      "   +- SortMergeJoin [word#0], [word#301], LeftAnti\n",
      "      :- *(1) Sort [word#0 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(word#0, 200)\n",
      "      :     +- Scan ExistingRDD[word#0,count#1L]\n",
      "      +- *(3) Sort [word#301 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(word#301, 200)\n",
      "            +- *(2) Project [word#301]\n",
      "               +- Scan ExistingRDD[word#301]\n"
     ]
    }
   ],
   "source": [
    "nostop.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_sw = broadcast(swdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_sw.createOrReplaceTempView(\"bc_stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_nostop = spark.sql(\"select /*+ broadcast(s) */* from wordcount w where not exists (select 1 from bc_stop s where s.word = w.word) order by 2 desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "| thou| 5138|\n",
      "|  thy| 4028|\n",
      "|shall| 3473|\n",
      "| good| 2560|\n",
      "|would| 2240|\n",
      "|  let| 2089|\n",
      "|enter| 2013|\n",
      "| hath| 1902|\n",
      "| thee| 1794|\n",
      "|  may| 1747|\n",
      "| i'll| 1737|\n",
      "| king| 1698|\n",
      "| upon| 1664|\n",
      "| like| 1641|\n",
      "| make| 1596|\n",
      "|  one| 1486|\n",
      "| you,| 1479|\n",
      "| must| 1449|\n",
      "| know| 1402|\n",
      "| 'tis| 1367|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bc_nostop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [count#1L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(count#1L DESC NULLS LAST, 200)\n",
      "   +- *(2) BroadcastHashJoin [word#0], [word#301], LeftAnti, BuildRight\n",
      "      :- Scan ExistingRDD[word#0,count#1L]\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "         +- *(1) Project [word#301]\n",
      "            +- Scan ExistingRDD[word#301]\n"
     ]
    }
   ],
   "source": [
    "bc_nostop.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bc_nostop.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}